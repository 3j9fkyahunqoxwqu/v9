---
title: Bayesian Gaussian Process Latent Variable Model
abstract: We introduce a variational inference framework for training the Gaussian
  process latent variable model and thus performing Bayesian nonlinear dimensionality
  reduction. This method allows us to variationally integrate out the input variables
  of the Gaussian process and compute a lower bound on the exact marginal likelihood
  of the nonlinear latent variable model. The maximization of the variational lower
  bound provides a Bayesian training procedure that is robust to overfitting and can
  automatically select the dimensionality of the nonlinear latent space. We demonstrate
  our method on real world datasets. The focus in this paper is on dimensionality
  reduction problems, but the methodology is more general. For example, our algorithm
  is immediately applicable for training Gaussian process models in the presence of
  missing or uncertain inputs.
pdf: http://proceedings.mlr.press/v9/titsias10a/titsias10a.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: titsias10a
month: 0
firstpage: 844
lastpage: 851
page: 844-851
sections: 
author:
- given: Michalis
  family: Titsias
- given: Neil
  family: Lawrence
date: 2010-03-31
address: Chia Laguna Resort, Sardinia, Italy
publisher: PMLR
container-title: Proceedings of the Thirteenth International Conference on Artificial
  Intelligence and Statistics
volume: '9'
genre: inproceedings
issued:
  date-parts:
  - 2010
  - 3
  - 31
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
