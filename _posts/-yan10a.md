---
title: 'Modeling annotator expertise: Learning when everybody knows a bit of something'
abstract: Supervised learning from multiple labeling sources is an increasingly important
  problem in machine learning and data mining. This paper develops a probabilistic
  approach to this problem when annotators may be unreliable (labels are noisy), but
  also their expertise varies depending on the data they observe (annotators may have
  knowledge about different parts of the input space). That is, an annotator may not
  be consistently accurate (or inaccurate) across the task domain. The presented approach
  produces classification and annotator models that allow us to provide estimates
  of the true labels and annotator variable expertise. We provide an analysis of the
  proposed model under various scenarios and show experimentally that annotator expertise
  can indeed vary in real tasks and that the presented approach provides clear advantages
  over previously introduced multi-annotator methods, which only consider general
  annotator characteristics.
pdf: "./yan10a/yan10a.pdf"
layout: inproceedings
key: yan10a
month: 0
firstpage: 932
lastpage: 939
origpdf: http://jmlr.org/proceedings/papers/v9/yan10a/yan10a.pdf
sections: 
authors:
- given: Yan
  family: Yan
- given: Romer
  family: Rosales
- given: Glenn
  family: Fung
- given: Mark
  family: Schmidt
- given: Gerardo
  family: Hermosillo
- given: Luca
  family: Bogoni
- given: Linda
  family: Moy
- given: Jennifer
  family: Dy
---
