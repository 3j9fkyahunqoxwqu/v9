---
title: Dependent Indian Buffet Processes
abstract: Latent variable models represent hidden structure in observational data.To
  account for the distribution of the observational data changing over time, space
  or some other covariate, we need generalizations of latent variable models that
  explicitly capture this dependency on the covariate. A variety of such generalizations
  has been proposed for latent variable models based on the Dirichlet process. We
  address dependency on covariates in binary latent feature models, by introducing
  a dependent Indian buffet process. The model generates, for each value of the covariate,
  a binary random matrix with an unbounded number of columns.  Evolution of the binary
  matrices over the covariate set is controlled by a hierarchical Gaussian process
  model. The choice of covariance functions controls the dependence structure and
  exchangeability properties of the model. We derive a Markov Chain Monte Carlo sampling
  algorithm for  Bayesian inference, and provide experiments on both synthetic and
  real-world data. The experimental results show that explicit modeling of dependencies
  significantly improves accuracy of predictions.
pdf: "./williamson10a/williamson10a.pdf"
layout: inproceedings
key: williamson10a
month: 0
firstpage: 924
lastpage: 931
origpdf: http://jmlr.org/proceedings/papers/v9/williamson10a/williamson10a.pdf
sections: 
authors:
- given: Sinead
  family: Williamson
- given: Peter
  family: Orbanz
- given: Zoubin
  family: Ghahramani
---
