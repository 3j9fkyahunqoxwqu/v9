---
title: Reduced-Rank Hidden Markov Models
abstract: Hsu et al.(2009) recently proposed an efficient, accurate spectral learning
  algorithm for Hidden Markov Models (HMMs). In this paper we relax their assumptions
  and prove a tighter finite-sample error bound for the case of Reduced-Rank HMMs,
  i.e., HMMs with low-rank transition matrices. Since rank-k RR-HMMs are a larger
  class of models than k-state HMMs while being equally efficient to work with, this
  relaxation greatly increases the learning algorithm's scope. In addition, we generalize
  the algorithm and bounds to models where multiple observations are needed to disambiguate
  state, and to models that emit multivariate real-valued observations. Finally we
  prove consistency for learning Predictive State Representations, an even larger
  class of models. Experiments on synthetic data and a toy video, as well as on difficult
  robot vision data, yield accurate models that compare favorably with alternatives
  in simulation quality and prediction accuracy.
pdf: "./siddiqi10a/siddiqi10a.pdf"
layout: inproceedings
id: siddiqi10a
month: 0
firstpage: 741
lastpage: 748
page: 741-748
origpdf: http://jmlr.org/proceedings/papers/v9/siddiqi10a/siddiqi10a.pdf
sections: 
author:
- given: Sajid
  family: Siddiqi
- given: Byron
  family: Boots
- given: Geoffrey
  family: Gordon
date: '2010-03-31 00:12:21'
publisher: PMLR
---
