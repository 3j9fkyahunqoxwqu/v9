---
title: Dependent Indian Buffet Processes
abstract: Latent variable models represent hidden structure in observational data.To
  account for the distribution of the observational data changing over time, space
  or some other covariate, we need generalizations of latent variable models that
  explicitly capture this dependency on the covariate. A variety of such generalizations
  has been proposed for latent variable models based on the Dirichlet process. We
  address dependency on covariates in binary latent feature models, by introducing
  a dependent Indian buffet process. The model generates, for each value of the covariate,
  a binary random matrix with an unbounded number of columns.  Evolution of the binary
  matrices over the covariate set is controlled by a hierarchical Gaussian process
  model. The choice of covariance functions controls the dependence structure and
  exchangeability properties of the model. We derive a Markov Chain Monte Carlo sampling
  algorithm for  Bayesian inference, and provide experiments on both synthetic and
  real-world data. The experimental results show that explicit modeling of dependencies
  significantly improves accuracy of predictions.
pdf: http://jmlr.org/proceedings/papers/v9/williamson10a/williamson10a.pdf
layout: inproceedings
id: williamson10a
month: 0
firstpage: 924
lastpage: 931
page: 924-931
sections: 
author:
- given: Sinead
  family: Williamson
- given: Peter
  family: Orbanz
- given: Zoubin
  family: Ghahramani
reponame: v9
date: 2010-03-31
address: Chia Laguna Resort, Sardinia, Italy
publisher: PMLR
container-title: Proceedings of the Thirteenth International Conference on Artificial
  Intelligence and Statistics
volume: '9'
genre: inproceedings
issued:
  date-parts:
  - 2010
  - 3
  - 31
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
