---
title: Exploiting Feature Covariance in High-Dimensional Online Learning
abstract: Some online algorithms for linear classification model the uncertainty in
  their weights over the course of learning.  Modeling the full covariance structure
  of the weights can provide a significant advantage for classification.  However,
  for high-dimensional, large-scale data, even though there may be many second-order
  feature interactions, it is computationally infeasible to maintain this covariance
  structure. To extend second-order methods to high-dimensional data, we develop low-rank
  approximations of the covariance structure. We evaluate our approach on both synthetic
  and real-world data sets using the confidence-weighted online learning framework.
  We show improvements over diagonal covariance matrices for both low and high-dimensional
  data.
pdf: http://jmlr.org/proceedings/papers/v9/ma10a/ma10a.pdf
layout: inproceedings
id: ma10a
month: 0
firstpage: 493
lastpage: 500
page: 493-500
sections: 
author:
- given: Justin
  family: Ma
- given: Alex
  family: Kulesza
- given: Mark
  family: Dredze
- given: Koby
  family: Crammer
- given: Lawrence
  family: Saul
- given: Fernando
  family: Pereira
reponame: v9
date: 2010-03-31
address: Chia Laguna Resort, Sardinia, Italy
publisher: PMLR
container-title: Proceedings of the Thirteenth International Conference on Artificial
  Intelligence and Statistics
volume: '9'
genre: inproceedings
issued:
  date-parts:
  - 2010
  - 3
  - 31
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
