---
title: Learning the Structure of Deep Sparse Graphical Models
abstract: Deep belief networks are a powerful way to model complex probability   distributions.  However,
  it is difficult to learn the structure of a   belief network, particularly one with
  hidden units.  The Indian   buffet process has been used as a nonparametric Bayesian
  prior on   the structure of a directed belief network with a single infinitely   wide
  hidden layer. Here, we introduce the cascading Indian   buffet process (CIBP), which
  provides a prior on the structure of a   layered, directed belief network that is
  unbounded in both depth and   width, yet allows tractable inference.  We use the
  CIBP prior with   the nonlinear Gaussian belief network framework to allow each
  unit   to vary its behavior between discrete and continuous   representations.  We
  use Markov chain Monte Carlo for inference in   this model and explore the structures
  learned on image data.
pdf: "./adams10a/adams10a.pdf"
supplementary: Supplementary:http://jmlr.org/proceedings/papers/v9/adams10a/adams10aSupple.pdf
layout: inproceedings
key: adams10a
month: 0
firstpage: 1
lastpage: 8
origpdf: http://jmlr.org/proceedings/papers/v9/adams10a/adams10a.pdf
sections: 
authors:
- given: Ryan
  family: Adams
- given: Hanna
  family: Wallach
- given: Zoubin
  family: Ghahramani
---
